% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gp.functions6.R
\name{gpr}
\alias{gpr}
\title{Gaussian Process regression}
\usage{
gpr(
  Data,
  response,
  Cov = "pow.ex",
  m = NULL,
  hyper = NULL,
  NewHyper = NULL,
  meanModel = 0,
  mean = NULL,
  gamma = NULL,
  nu = NULL,
  useGradient = T,
  itermax = 100,
  reltol = 8e-10,
  trace = 0,
  nInitCandidates = 1000
)
}
\arguments{
\item{Data}{The input data from train data. Matrix or vectors are both
acceptable. Some data.frames are not acceptable.}

\item{response}{The response data from train data. Matrix or vectors are both
acceptable. Some data.frames are not acceptable.}

\item{Cov}{Covariance function(s) to use. Default to 'power.ex'.}

\item{m}{If Subset of Data is to be used, m denotes the subset size and
cannot be larger than the total sample size. Default set to NULL.}

\item{hyper}{The hyperparameters. Default to NULL. If not NULL, then must be
a list with certain names.}

\item{NewHyper}{Vector of the names of the new hyper parameters from
customized kernel function. The names of the hyper-parameters must have the
format: xxxxxx.x, i.e. '6 digit' plus 'a dot' plus '1 digit'. This is
required for both 'hyper' and 'NewHyper'}

\item{meanModel}{Type of mean.}

\item{mean}{Is the mean taken out when analysis? Default to be 0, which
assumes the mean is zero. if assume mean is a constant, mean=1; if assume
mean is a linear trend, mean='t'.}

\item{gamma}{Power parameter used in powered exponential kernel function.}

\item{nu}{Smoothness parameter of the Matern class. Must be a positive value.}

\item{useGradient}{Logical. If TRUE, first derivatives will be used in the
optimization.}

\item{itermax}{Number of maximum iteration in optimization function. Default
to be 100. Normally the number of optimization steps is around 20. If
reduce 'reltol', the iterations needed will be less.}

\item{reltol}{Relative convergence tolerance. Smaller reltol means more
accurate and slower to converge.}

\item{trace}{The value of the objective function and the parameters is
printed every trace'th iteration. Defaults to 0 which indicates no trace
information is to be printed.}

\item{nInitCandidates}{Number of initial hyperparameter vectors. The
optimization starts with the best.}
}
\value{
A list containing: \describe{ 
\item{hyper}{Hyper-parameter estimated from training data}
\item{var.hyper}{ Variance of the estimated hyper-parameters} 
\item{fitted.mean }{Fitted value of training data } 
\item{fitted.sd }{Standard deviation of the fitted value of training data} 
\item{train.x }{ Training covariates} 
\item{train.y }{ Training response} 
\item{ train.yOri}{Original training response } 
\item{train.DataOri }{ } 
\item{idxSubset }{Index vector identifying which observations were selected 
if Subset of Data was used.} 
\item{ CovFun}{ Covariance function type} 
\item{ gamma}{Parameter used in powered exponential covariance function } 
\item{nu }{Parameter used in Matern covariance function } 
\item{Q}{Covariance matrix } 
\item{mean}{Mean function } 
\item{meanModel}{ CHECK: 'lm' object if mean is a linear regression. NULL otherwise.} 
\item{meanLinearModel}{ } 
\item{conv}{0 means converge; 1 otherwise. } 
\item{hyper0}{ starting point of the hyper-parameters}
 }
}
\description{
Gaussian Process regression for a single or multiple independent
realisations.
}
\details{
The most important function in the package, for fitting the GP model
  and store everything necessary for prediction. The optimization used in the
  function is 'nlminb'. Optimization might break down if the noise for the
  curve are too far away from normal. Jitter, LU decomposition and sparse
  matrix inverse are used to ensure the matrix inverse can always get an
  answer. The names for the hyper parameters should be:"linear.a" for linear
  covariance function, "pow.ex.w", "pow.ex.v" for power exponential,
  "rat.qu.s", "rat.qu.a" for rational quadratic, "matern" for Matern, "vv"
  for Gaussian white noise. All hyper parameters should be in one list.
}
\references{
Shi, J. Q., and Choi, T. (2011), ``Gaussian Process Regression
  Analysis for Functional Data'', CRC Press.
}
